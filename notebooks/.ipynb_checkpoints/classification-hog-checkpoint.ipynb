{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /usr/local/envs/py3env/lib/python3.5/site-packages (0.13.0)\n",
      "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/envs/py3env/lib/python3.5/site-packages (from scikit-image) (2.1.2)\n",
      "Requirement already satisfied: six>=1.7.3 in /usr/local/envs/py3env/lib/python3.5/site-packages (from scikit-image) (1.10.0)\n",
      "Requirement already satisfied: networkx>=1.8 in /usr/local/envs/py3env/lib/python3.5/site-packages (from scikit-image) (2.1)\n",
      "Requirement already satisfied: pillow>=2.1.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from scikit-image) (3.4.1)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from scikit-image) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /usr/local/envs/py3env/lib/python3.5/site-packages (from matplotlib>=1.3.1->scikit-image) (1.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/envs/py3env/lib/python3.5/site-packages (from matplotlib>=1.3.1->scikit-image) (2.5.0)\n",
      "Requirement already satisfied: pytz in /usr/local/envs/py3env/lib/python3.5/site-packages (from matplotlib>=1.3.1->scikit-image) (2018.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/envs/py3env/lib/python3.5/site-packages (from matplotlib>=1.3.1->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/envs/py3env/lib/python3.5/site-packages (from matplotlib>=1.3.1->scikit-image) (2.2.1)\n",
      "Requirement already satisfied: decorator>=4.1.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from networkx>=1.8->scikit-image) (4.3.0)\n",
      "Requirement already satisfied: keras in /usr/local/envs/py3env/lib/python3.5/site-packages (2.2.4)\n",
      "Requirement already satisfied: h5py in /usr/local/envs/py3env/lib/python3.5/site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/envs/py3env/lib/python3.5/site-packages (from keras) (1.0.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from keras) (1.10.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/envs/py3env/lib/python3.5/site-packages (from keras) (3.13)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/envs/py3env/lib/python3.5/site-packages (from keras) (1.0.9)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/envs/py3env/lib/python3.5/site-packages (from keras) (1.0.7)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/envs/py3env/lib/python3.5/site-packages (from keras) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage import feature\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOG + Baseline model with augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset: str, channels: int = 1, augmentation: bool = True):\n",
    "\n",
    "    df = pd.read_csv(dataset)\n",
    "\n",
    "    df['category'] = df['category'].str.strip()\n",
    "\n",
    "    train = df.loc[df.category == 'Training',:]\n",
    "    valid = df.loc[df.category == 'PublicTest',:]\n",
    "    test  = df.loc[df.category == 'PrivateTest',:]\n",
    "\n",
    "    del train['Unnamed: 0']\n",
    "    del valid['Unnamed: 0']\n",
    "    del test['Unnamed: 0']\n",
    "\n",
    "    X_train = np.array(train.iloc[:, 1:2305])\n",
    "    y_train = np.array(train.loc[:, ['y']])\n",
    "\n",
    "    X_val = np.array(valid.iloc[:, 1:2305])\n",
    "    y_val = np.array(valid.loc[:, ['y']])\n",
    "\n",
    "    X_test = np.array(test.iloc[:, 1:2305])\n",
    "    y_test = np.array(test.loc[:, ['y']])\n",
    "\n",
    "    del train\n",
    "    del valid\n",
    "    del test\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train, 7)\n",
    "    y_val = keras.utils.to_categorical(y_val, 7)\n",
    "    y_test = keras.utils.to_categorical(y_test, 7)\n",
    "\n",
    "    X_train_r = X_train.reshape((len(X_train), 48, 48))\n",
    "    X_val_r   = X_val.reshape((len(X_val), 48, 48))\n",
    "    X_test_r   = X_test.reshape((len(X_test), 48, 48))\n",
    "\n",
    "    X_train_r = X_train_r / 255\n",
    "    X_val_r = X_val_r / 255\n",
    "    X_test_r = X_test_r / 255\n",
    "\n",
    "    if channels == 1:\n",
    "        X_train_bw = X_train_r.reshape((len(X_train_r), 48, 48, 1))\n",
    "        X_val_bw = X_val_r.reshape((len(X_val_r), 48, 48, 1))\n",
    "        X_test_bw = X_test_r.reshape((len(X_test_r), 48, 48, 1))\n",
    "        return (X_train_bw, X_val_bw, X_test_bw, y_train, y_val, y_test)\n",
    "    elif channels == 3:\n",
    "        X_train_rgb = np.stack((X_train_r,) * 3, axis = -1)\n",
    "        X_val_rgb = np.stack((X_val_r, ) * 3, axis = -1)\n",
    "        X_test_rgb = np.stack((X_test_r, ) * 3, axis = -1)\n",
    "        return (X_train_rgb, X_val_rgb, X_test_rgb, y_train, y_val, y_test)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bw, X_val_bw, X_test_bw, y_train, y_val, y_test = load_data('emotions.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_train = np.zeros((len(X_train_bw), 1296))\n",
    "\n",
    "for i in range(len(X_train_bw)):\n",
    "    hog_train[i] = feature.hog(X_train_bw[i].reshape((48,48)), block_norm='L2-Hys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_val = np.zeros((len(X_val_bw), 1296))\n",
    "\n",
    "for i in range(len(X_val_bw)):\n",
    "    hog_val[i] = feature.hog(X_val_bw[i].reshape((48,48)), block_norm='L2-Hys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_test = np.zeros((len(X_test_bw), 1296))\n",
    "\n",
    "for i in range(len(X_test_bw)):\n",
    "    hog_test[i] = feature.hog(X_test_bw[i].reshape((48,48)), block_norm='L2-Hys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.metrics import categorical_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_input = keras.layers.Input(shape=(1296,))\n",
    "\n",
    "image_input = keras.layers.Input(shape=(48, 48, 1))\n",
    "\n",
    "conv1 = Conv2D(64,(3,3), padding='same')(image_input)\n",
    "batch1 = BatchNormalization()(conv1)\n",
    "activ1 = Activation('relu')(batch1)\n",
    "maxpo1 = MaxPooling2D(pool_size=(2, 2))(activ1)\n",
    "dropo1 = Dropout(0.5)(maxpo1)\n",
    "\n",
    "conv2 = Conv2D(128,(5,5), padding='same')(dropo1)\n",
    "batch2 = BatchNormalization()(conv2)\n",
    "activ2 = Activation('relu')(batch2)\n",
    "maxpo2 = MaxPooling2D(pool_size=(2, 2))(activ2)\n",
    "dropo2 = Dropout(0.5)(maxpo2)\n",
    "\n",
    "conv3 = Conv2D(512,(3,3), padding='same')(dropo2)\n",
    "batch3 = BatchNormalization()(conv3)\n",
    "activ3 = Activation('relu')(batch3)\n",
    "maxpo3 = MaxPooling2D(pool_size=(2, 2))(activ3)\n",
    "dropo3 = Dropout(0.5)(maxpo3)\n",
    "\n",
    "conv4 = Conv2D(512,(3,3), padding='same')(dropo3)\n",
    "batch4 = BatchNormalization()(conv4)\n",
    "activ4 = Activation('relu')(batch4)\n",
    "maxpo4 = MaxPooling2D(pool_size=(2, 2))(activ4)\n",
    "dropo4 = Dropout(0.5)(maxpo4)\n",
    "\n",
    "flatt4 = Flatten()(dropo4)\n",
    "\n",
    "# hog_dense = Dense(1296)(hog_input)\n",
    "\n",
    "dense1 = Concatenate()([hog_input, flatt4])\n",
    "\n",
    "dense2 = Dense(256)(dense1)\n",
    "batch5 = BatchNormalization()(dense2)\n",
    "activ5 = Activation('relu')(batch5)\n",
    "dropo5 = Dropout(0.5)(activ5)\n",
    "\n",
    "dense3 = Dense(512)(dropo5)\n",
    "batch6 = BatchNormalization()(dense3)\n",
    "activ6 = Activation('relu')(batch6)\n",
    "dropo6 = Dropout(0.5)(activ6)\n",
    "\n",
    "dense4 = Dense(512)(dropo6)\n",
    "batch7 = BatchNormalization()(dense4)\n",
    "activ7 = Activation('relu')(batch7)\n",
    "dropo7 = Dropout(0.5)(activ7)\n",
    "\n",
    "out = Dense(7, activation='softmax')(dropo7)\n",
    "\n",
    "model = keras.models.Model(inputs=[image_input, hog_input], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_28 (InputLayer)           (None, 48, 48, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 48, 48, 64)   640         input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 48, 48, 64)   256         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 48, 48, 64)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling2D) (None, 24, 24, 64)   0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 24, 24, 64)   0           max_pooling2d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 24, 24, 128)  204928      dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 24, 24, 128)  512         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 24, 24, 128)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling2D) (None, 12, 12, 128)  0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 12, 12, 128)  0           max_pooling2d_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 512)  590336      dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 512)  2048        conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 512)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling2D) (None, 6, 6, 512)    0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 6, 6, 512)    0           max_pooling2d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 6, 6, 512)    2359808     dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 6, 6, 512)    2048        conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 6, 6, 512)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling2D) (None, 3, 3, 512)    0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 3, 3, 512)    0           max_pooling2d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_27 (InputLayer)           (None, 1296)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 4608)         0           dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 5904)         0           input_27[0][0]                   \n",
      "                                                                 flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 256)          1511680     concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 256)          1024        dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 256)          0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 256)          0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 512)          131584      dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 512)          2048        dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 512)          0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 512)          0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 512)          262656      dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 512)          2048        dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 512)          0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 512)          0           activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 7)            3591        dropout_62[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 5,075,207\n",
      "Trainable params: 5,070,215\n",
      "Non-trainable params: 4,992\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 1.2015 - categorical_accuracy: 0.5414 - val_loss: 1.2018 - val_categorical_accuracy: 0.5447\n",
      "Epoch 2/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 1.1853 - categorical_accuracy: 0.5495 - val_loss: 1.3540 - val_categorical_accuracy: 0.4700\n",
      "Epoch 3/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 1.1595 - categorical_accuracy: 0.5631 - val_loss: 1.3280 - val_categorical_accuracy: 0.4737\n",
      "Epoch 4/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 1.1389 - categorical_accuracy: 0.5706 - val_loss: 1.1714 - val_categorical_accuracy: 0.5511\n",
      "Epoch 5/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 1.1315 - categorical_accuracy: 0.5686 - val_loss: 1.2014 - val_categorical_accuracy: 0.5436\n",
      "Epoch 6/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 1.1042 - categorical_accuracy: 0.5844 - val_loss: 1.1661 - val_categorical_accuracy: 0.5517\n",
      "Epoch 7/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 1.0886 - categorical_accuracy: 0.5910 - val_loss: 1.1572 - val_categorical_accuracy: 0.5653\n",
      "Epoch 8/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 1.0674 - categorical_accuracy: 0.5971 - val_loss: 1.3231 - val_categorical_accuracy: 0.5013\n",
      "Epoch 9/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 1.0529 - categorical_accuracy: 0.6047 - val_loss: 1.2682 - val_categorical_accuracy: 0.5210\n",
      "Epoch 10/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 1.0300 - categorical_accuracy: 0.6097 - val_loss: 1.2154 - val_categorical_accuracy: 0.5425\n",
      "Epoch 11/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 1.0180 - categorical_accuracy: 0.6195 - val_loss: 1.0801 - val_categorical_accuracy: 0.5982\n",
      "Epoch 12/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.9980 - categorical_accuracy: 0.6259 - val_loss: 1.2151 - val_categorical_accuracy: 0.5525\n",
      "Epoch 13/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.9760 - categorical_accuracy: 0.6359 - val_loss: 1.1451 - val_categorical_accuracy: 0.5712\n",
      "Epoch 14/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.9617 - categorical_accuracy: 0.6412 - val_loss: 1.1056 - val_categorical_accuracy: 0.5901\n",
      "Epoch 15/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.9498 - categorical_accuracy: 0.6441 - val_loss: 1.2156 - val_categorical_accuracy: 0.5495\n",
      "Epoch 16/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.9274 - categorical_accuracy: 0.6550 - val_loss: 1.1254 - val_categorical_accuracy: 0.5907\n",
      "Epoch 17/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.9107 - categorical_accuracy: 0.6608 - val_loss: 1.0885 - val_categorical_accuracy: 0.6046\n",
      "Epoch 18/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.8942 - categorical_accuracy: 0.6648 - val_loss: 1.1221 - val_categorical_accuracy: 0.5932\n",
      "Epoch 19/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.8718 - categorical_accuracy: 0.6732 - val_loss: 1.0977 - val_categorical_accuracy: 0.5993\n",
      "Epoch 20/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.8661 - categorical_accuracy: 0.6769 - val_loss: 1.2112 - val_categorical_accuracy: 0.5517\n",
      "Epoch 21/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.8424 - categorical_accuracy: 0.6888 - val_loss: 1.1347 - val_categorical_accuracy: 0.5882\n",
      "Epoch 22/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.8305 - categorical_accuracy: 0.6917 - val_loss: 1.1273 - val_categorical_accuracy: 0.5965\n",
      "Epoch 23/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.8049 - categorical_accuracy: 0.7012 - val_loss: 1.2061 - val_categorical_accuracy: 0.5690\n",
      "Epoch 24/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.7944 - categorical_accuracy: 0.7065 - val_loss: 1.1734 - val_categorical_accuracy: 0.5776\n",
      "Epoch 25/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.7748 - categorical_accuracy: 0.7110 - val_loss: 1.1294 - val_categorical_accuracy: 0.5977\n",
      "Epoch 26/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.7634 - categorical_accuracy: 0.7160 - val_loss: 1.2448 - val_categorical_accuracy: 0.5759\n",
      "Epoch 27/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.7542 - categorical_accuracy: 0.7226 - val_loss: 1.1485 - val_categorical_accuracy: 0.5949\n",
      "Epoch 28/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.7453 - categorical_accuracy: 0.7255 - val_loss: 1.2381 - val_categorical_accuracy: 0.5592\n",
      "Epoch 29/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.7167 - categorical_accuracy: 0.7353 - val_loss: 1.1550 - val_categorical_accuracy: 0.5952\n",
      "Epoch 30/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.7112 - categorical_accuracy: 0.7372 - val_loss: 1.2014 - val_categorical_accuracy: 0.5770\n",
      "Epoch 31/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.6992 - categorical_accuracy: 0.7461 - val_loss: 1.1729 - val_categorical_accuracy: 0.5996\n",
      "Epoch 32/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.6918 - categorical_accuracy: 0.7454 - val_loss: 1.1992 - val_categorical_accuracy: 0.6035\n",
      "Epoch 33/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.6757 - categorical_accuracy: 0.7505 - val_loss: 1.2935 - val_categorical_accuracy: 0.5595\n",
      "Epoch 34/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.6669 - categorical_accuracy: 0.7571 - val_loss: 1.1803 - val_categorical_accuracy: 0.5857\n",
      "Epoch 35/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.6543 - categorical_accuracy: 0.7598 - val_loss: 1.2009 - val_categorical_accuracy: 0.5887\n",
      "Epoch 36/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.6439 - categorical_accuracy: 0.7654 - val_loss: 1.1536 - val_categorical_accuracy: 0.5957\n",
      "Epoch 37/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.6374 - categorical_accuracy: 0.7682 - val_loss: 1.1677 - val_categorical_accuracy: 0.5924\n",
      "Epoch 38/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.6221 - categorical_accuracy: 0.7730 - val_loss: 1.2220 - val_categorical_accuracy: 0.5985\n",
      "Epoch 39/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.6077 - categorical_accuracy: 0.7766 - val_loss: 1.2918 - val_categorical_accuracy: 0.5628\n",
      "Epoch 40/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.6007 - categorical_accuracy: 0.7803 - val_loss: 1.3141 - val_categorical_accuracy: 0.5651\n",
      "Epoch 41/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.5957 - categorical_accuracy: 0.7807 - val_loss: 1.1608 - val_categorical_accuracy: 0.5857\n",
      "Epoch 42/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.5897 - categorical_accuracy: 0.7840 - val_loss: 1.2029 - val_categorical_accuracy: 0.6071\n",
      "Epoch 43/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.5790 - categorical_accuracy: 0.7878 - val_loss: 1.2643 - val_categorical_accuracy: 0.5876\n",
      "Epoch 44/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.5628 - categorical_accuracy: 0.7953 - val_loss: 1.2410 - val_categorical_accuracy: 0.5901\n",
      "Epoch 45/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.5518 - categorical_accuracy: 0.7984 - val_loss: 1.2310 - val_categorical_accuracy: 0.5874\n",
      "Epoch 46/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.5455 - categorical_accuracy: 0.8012 - val_loss: 1.2341 - val_categorical_accuracy: 0.5690\n",
      "Epoch 47/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.5445 - categorical_accuracy: 0.8015 - val_loss: 1.2512 - val_categorical_accuracy: 0.5893\n",
      "Epoch 48/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.5357 - categorical_accuracy: 0.8056 - val_loss: 1.1806 - val_categorical_accuracy: 0.5988\n",
      "Epoch 49/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.5190 - categorical_accuracy: 0.8092 - val_loss: 1.2232 - val_categorical_accuracy: 0.6004\n",
      "Epoch 50/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.5208 - categorical_accuracy: 0.8109 - val_loss: 1.2810 - val_categorical_accuracy: 0.5779\n",
      "Epoch 51/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.5193 - categorical_accuracy: 0.8110 - val_loss: 1.1951 - val_categorical_accuracy: 0.6069\n",
      "Epoch 52/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.5088 - categorical_accuracy: 0.8155 - val_loss: 1.2581 - val_categorical_accuracy: 0.5979\n",
      "Epoch 53/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.5027 - categorical_accuracy: 0.8177 - val_loss: 1.1946 - val_categorical_accuracy: 0.5991\n",
      "Epoch 54/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.5038 - categorical_accuracy: 0.8174 - val_loss: 1.2128 - val_categorical_accuracy: 0.6016\n",
      "Epoch 55/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.4886 - categorical_accuracy: 0.8234 - val_loss: 1.3785 - val_categorical_accuracy: 0.5670\n",
      "Epoch 56/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.4876 - categorical_accuracy: 0.8225 - val_loss: 1.2152 - val_categorical_accuracy: 0.5726\n",
      "Epoch 57/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.4839 - categorical_accuracy: 0.8228 - val_loss: 1.2921 - val_categorical_accuracy: 0.5603\n",
      "Epoch 58/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.4769 - categorical_accuracy: 0.8270 - val_loss: 1.2295 - val_categorical_accuracy: 0.6202\n",
      "Epoch 59/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.4691 - categorical_accuracy: 0.8279 - val_loss: 1.3369 - val_categorical_accuracy: 0.5606\n",
      "Epoch 60/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.4646 - categorical_accuracy: 0.8313 - val_loss: 1.2576 - val_categorical_accuracy: 0.5918\n",
      "Epoch 61/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.4618 - categorical_accuracy: 0.8320 - val_loss: 1.2325 - val_categorical_accuracy: 0.5773\n",
      "Epoch 62/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.4515 - categorical_accuracy: 0.8351 - val_loss: 1.2908 - val_categorical_accuracy: 0.5704\n",
      "Epoch 63/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.4509 - categorical_accuracy: 0.8369 - val_loss: 1.2587 - val_categorical_accuracy: 0.6069\n",
      "Epoch 64/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.4438 - categorical_accuracy: 0.8367 - val_loss: 1.2640 - val_categorical_accuracy: 0.6080\n",
      "Epoch 65/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.4433 - categorical_accuracy: 0.8383 - val_loss: 1.3226 - val_categorical_accuracy: 0.5846\n",
      "Epoch 66/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.4288 - categorical_accuracy: 0.8432 - val_loss: 1.2747 - val_categorical_accuracy: 0.5993\n",
      "Epoch 67/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.4288 - categorical_accuracy: 0.8430 - val_loss: 1.3702 - val_categorical_accuracy: 0.5871\n",
      "Epoch 68/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.4265 - categorical_accuracy: 0.8466 - val_loss: 1.3340 - val_categorical_accuracy: 0.5862\n",
      "Epoch 69/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.4247 - categorical_accuracy: 0.8472 - val_loss: 1.2353 - val_categorical_accuracy: 0.6046\n",
      "Epoch 70/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.4150 - categorical_accuracy: 0.8486 - val_loss: 1.2502 - val_categorical_accuracy: 0.5726\n",
      "Epoch 71/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.4152 - categorical_accuracy: 0.8497 - val_loss: 1.3286 - val_categorical_accuracy: 0.5770\n",
      "Epoch 72/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.4134 - categorical_accuracy: 0.8504 - val_loss: 1.4724 - val_categorical_accuracy: 0.5261\n",
      "Epoch 73/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.4000 - categorical_accuracy: 0.8545 - val_loss: 1.3181 - val_categorical_accuracy: 0.5974\n",
      "Epoch 74/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.4022 - categorical_accuracy: 0.8533 - val_loss: 1.3456 - val_categorical_accuracy: 0.6027\n",
      "Epoch 75/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.4016 - categorical_accuracy: 0.8565 - val_loss: 1.3801 - val_categorical_accuracy: 0.5815\n",
      "Epoch 76/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.4003 - categorical_accuracy: 0.8521 - val_loss: 1.2660 - val_categorical_accuracy: 0.5943\n",
      "Epoch 77/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.3913 - categorical_accuracy: 0.8584 - val_loss: 1.4247 - val_categorical_accuracy: 0.5514\n",
      "Epoch 78/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.3970 - categorical_accuracy: 0.8560 - val_loss: 1.3434 - val_categorical_accuracy: 0.5952\n",
      "Epoch 79/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.3845 - categorical_accuracy: 0.8633 - val_loss: 1.3006 - val_categorical_accuracy: 0.5910\n",
      "Epoch 80/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.3873 - categorical_accuracy: 0.8585 - val_loss: 1.1978 - val_categorical_accuracy: 0.5949\n",
      "Epoch 81/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.3893 - categorical_accuracy: 0.8607 - val_loss: 1.2416 - val_categorical_accuracy: 0.6032\n",
      "Epoch 82/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.3666 - categorical_accuracy: 0.8684 - val_loss: 1.4264 - val_categorical_accuracy: 0.5770\n",
      "Epoch 83/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.3782 - categorical_accuracy: 0.8646 - val_loss: 1.2770 - val_categorical_accuracy: 0.5946\n",
      "Epoch 84/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.3724 - categorical_accuracy: 0.8663 - val_loss: 1.3083 - val_categorical_accuracy: 0.6030\n",
      "Epoch 85/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.3719 - categorical_accuracy: 0.8669 - val_loss: 1.2878 - val_categorical_accuracy: 0.5603\n",
      "Epoch 86/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.3762 - categorical_accuracy: 0.8647 - val_loss: 1.2576 - val_categorical_accuracy: 0.6130\n",
      "Epoch 87/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.3611 - categorical_accuracy: 0.8717 - val_loss: 1.3083 - val_categorical_accuracy: 0.5745\n",
      "Epoch 88/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.3683 - categorical_accuracy: 0.8674 - val_loss: 1.2875 - val_categorical_accuracy: 0.6052\n",
      "Epoch 89/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.3649 - categorical_accuracy: 0.8702 - val_loss: 1.2665 - val_categorical_accuracy: 0.6010\n",
      "Epoch 90/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.3555 - categorical_accuracy: 0.8716 - val_loss: 1.2498 - val_categorical_accuracy: 0.5913\n",
      "Epoch 91/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.3570 - categorical_accuracy: 0.8732 - val_loss: 1.3362 - val_categorical_accuracy: 0.6027\n",
      "Epoch 92/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.3517 - categorical_accuracy: 0.8758 - val_loss: 1.2937 - val_categorical_accuracy: 0.5745\n",
      "Epoch 93/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.3561 - categorical_accuracy: 0.8730 - val_loss: 1.3654 - val_categorical_accuracy: 0.5893\n",
      "Epoch 94/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.3493 - categorical_accuracy: 0.8735 - val_loss: 1.4229 - val_categorical_accuracy: 0.5913\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.3377 - categorical_accuracy: 0.8780 - val_loss: 1.3802 - val_categorical_accuracy: 0.6038\n",
      "Epoch 96/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.3414 - categorical_accuracy: 0.8784 - val_loss: 1.3387 - val_categorical_accuracy: 0.6127\n",
      "Epoch 97/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.3384 - categorical_accuracy: 0.8780 - val_loss: 1.2824 - val_categorical_accuracy: 0.5946\n",
      "Epoch 98/100\n",
      "28709/28709 [==============================] - 31s 1ms/step - loss: 0.3357 - categorical_accuracy: 0.8806 - val_loss: 1.3699 - val_categorical_accuracy: 0.5988\n",
      "Epoch 99/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.3411 - categorical_accuracy: 0.8781 - val_loss: 1.3574 - val_categorical_accuracy: 0.6004\n",
      "Epoch 100/100\n",
      "28709/28709 [==============================] - 30s 1ms/step - loss: 0.3348 - categorical_accuracy: 0.8804 - val_loss: 1.3192 - val_categorical_accuracy: 0.5974\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_bw, hog_train], y_train, batch_size=128, epochs=100, validation_data=([X_val_bw, hog_val], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3589/3589 [==============================] - 2s 482us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3224164700235752, 0.5962663694705496]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([X_test_bw, hog_test], y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
